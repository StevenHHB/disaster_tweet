
# DEMO: Disaster Tweet Classification Project

## Goal of the Problem

The primary objective of this project is to develop a predictive model capable of accurately determining whether a tweet is related to a real-life disaster. This binary classification task involves analyzing the text data within tweets to identify signals indicative of disaster-related content, differentiating them from everyday conversations or non-disaster-related topics.

## Data Preprocessing

The datasets consist of several columns, each representing different aspects of the tweet:

* **TEST Dataset Columns:**

  ```
  Index(['id', 'keyword', 'location', 'text'], dtype='object')

  ```
* **TRAIN Dataset Columns:**

    Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')

### Detailed Preprocessing Steps:

1. **Data Cleaning** :

* URLs, HTML tags, emojis, and special characters are removed to focus on the textual content.
* Missing values in `keyword` and `location` are filled with placeholders or inferred contextually.

1. **Tokenization** :

* Tweets are broken down into individual words or phrases, enabling the model to analyze them.

1. **Removing Stopwords** :

* Common words like "is", "at", "which" are removed, as they usually don't carry significant meaning relevant to disaster context.

1. **Stemming** :

* Words are reduced to their root form, allowing the model to generalize across different forms of the same word.

## Exploratory Data Analysis (EDA) and Data Visualization

The EDA phase involved comprehensive analysis and visualization to understand the underlying patterns within the data:

* Length distribution of tweets showed a tendency for longer tweets to be more associated with actual disasters.
* Common keywords were identified and their frequencies analyzed, revealing distinct patterns associated with disaster-related tweets.
* Sentiment analysis indicated that negative sentiment scores were more prevalent in disaster tweets.

Visuals such as bar graphs for keyword frequency, box plots for tweet length, and sentiment score distributions were utilized to convey these insights effectively.

## Model Training and Prediction

For this project, a Logistic Regression model was chosen for its efficiency and effectiveness in binary classification tasks involving textual data:

* The model was trained using TF-IDF vectors derived from the cleaned tweet texts, incorporating both unigrams and bigrams to capture context.
* Hyperparameter tuning was conducted using cross-validation to find the optimal balance between bias and variance.
* The model's performance was rigorously evaluated on a validation set using metrics such as F1-score, precision, and recall, ensuring its reliability for the classification task.

## Submission Process

The final predictions are compiled into a submission file formatted as per the competition's guidelines:

* The submission file includes two columns: `id` and `target`, where `id` corresponds to the tweet's identifier, and `target` is the predicted label (1 for disaster, 0 for non-disaster).
* Predictions were generated by applying the trained model to the preprocessed text data of the test set, ensuring consistency with the training phase.
* The submission file is saved in CSV format and is ready for submission to the competition's evaluation server.

## How to Use This Repository

To replicate the results or further develop the model, follow these steps:

* Clone the repository to your local machine.
* Install the required dependencies listed in the `requirements.txt` file.
* Execute the preprocessing script to clean and prepare the data: `python preprocess.py`.
* Run the training script to build and evaluate the model: `python predict.py`.
* Generate the submission file using: `python submission.py`.

Ensure you have the necessary data files (`train.csv` and `test.csv`) in the specified directories and adjust any paths in the scripts as needed.
